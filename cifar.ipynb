{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, val_data, batch_size, num_class):\n",
    "    net.eval()\n",
    "\n",
    "    val_data_iter = data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    use_cuda = net.use_cuda\n",
    "    \n",
    "    total_count = torch.zeros(size=(num_class,), dtype=torch.float32)\n",
    "    true_count = torch.zeros(size=(num_class,), dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (val_data, label) in enumerate(val_data_iter):\n",
    "            if use_cuda:\n",
    "                val_data = val_data.cuda()\n",
    "                label = label.cuda()\n",
    "            prediction = net(val_data)\n",
    "            _, pred = torch.max(prediction, 1)\n",
    "            predict_tensor = (pred == label).squeeze()\n",
    "            for i, true_label in enumerate(label):\n",
    "                total_count[true_label] += 1\n",
    "                true_count[true_label] += predict_tensor[i].item()\n",
    "            \n",
    "    precision = true_count.sum().item() / total_count.sum()\n",
    "    average_precision = true_count / total_count\n",
    "    mean_ap = average_precision.mean().item()\n",
    "    res_dct = {'precision': precision, 'map': mean_ap}\n",
    "    return res_dct, average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_layer(activation='relu'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param activation:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if activation == 'relu':\n",
    "        activation_layer = nn.ReLU()\n",
    "    elif activation == 'leaky_relu':\n",
    "        activation_layer = nn.LeakyReLU(0.1)\n",
    "    elif activation == 'sigmoid':\n",
    "        activation_layer = nn.Sigmoid()\n",
    "    elif activation == 'selu':\n",
    "        activation_layer = nn.SELU()\n",
    "    elif activation == 'elu':\n",
    "        activation_layer = nn.ELU()\n",
    "    elif activation == 'tanh':\n",
    "        activation_layer = nn.Tanh()\n",
    "    else:\n",
    "        activation_layer = None\n",
    "\n",
    "    return activation_layer\n",
    "\n",
    "\n",
    "def get_conv_block(dimension,\n",
    "                   in_channels,\n",
    "                   out_channels,\n",
    "                   kernel_size,\n",
    "                   stride,\n",
    "                   padding,\n",
    "                   activation = 'relu',\n",
    "                   batch_normalize=True,\n",
    "                   dropout=None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param dimension:\n",
    "    :param in_channels:\n",
    "    :param out_channels:\n",
    "    :param kernel_size:\n",
    "    :param stride:\n",
    "    :param padding:\n",
    "    :param activation:\n",
    "    :param batch_normalize:\n",
    "    :param dropout:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if batch_normalize:\n",
    "        bias = False\n",
    "    else:\n",
    "        bias = True\n",
    "\n",
    "    model = nn.Sequential()\n",
    "    if dimension == 1:\n",
    "        conv_layer = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                               bias=bias)\n",
    "        bn_layer = nn.BatchNorm1d(out_channels)\n",
    "    elif dimension == 2:\n",
    "        conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                               bias=bias)\n",
    "        bn_layer = nn.BatchNorm2d(out_channels)\n",
    "    elif dimension == 3:\n",
    "        conv_layer = nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                               bias=bias)\n",
    "        bn_layer = nn.BatchNorm3d(out_channels)\n",
    "    else:\n",
    "        raise ValueError(f'dimension value {dimension} is illegal, should be 1, 2, 3')\n",
    "    model.add_module('convolution', conv_layer)\n",
    "\n",
    "    activation_layer = get_activation_layer(activation)\n",
    "\n",
    "    if activation_layer is not None:\n",
    "        model.add_module('activation', activation_layer)\n",
    "\n",
    "    if batch_normalize:\n",
    "        model.add_module('bn', bn_layer)\n",
    "    elif dropout is not None:\n",
    "        model.add_module('dropout', nn.Dropout(dropout))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_conv_block1d(in_channels,\n",
    "                     out_channels,\n",
    "                     kernel_size=3,\n",
    "                     stride=1,\n",
    "                     padding=0,\n",
    "                     activation='relu',\n",
    "                     batch_normalize=True,\n",
    "                     dropout=None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param in_channels:\n",
    "    :param out_channels:\n",
    "    :param kernel_size:\n",
    "    :param stride:\n",
    "    :param padding:\n",
    "    :param activation:\n",
    "    :param batch_normalize:\n",
    "    :param dropout:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return get_conv_block(1,\n",
    "                          in_channels,\n",
    "                          out_channels,\n",
    "                          kernel_size,\n",
    "                          stride,\n",
    "                          padding,\n",
    "                          activation,\n",
    "                          batch_normalize,\n",
    "                          dropout)\n",
    "\n",
    "\n",
    "def get_conv_block2d(in_channels,\n",
    "                     out_channels,\n",
    "                     kernel_size=3,\n",
    "                     stride=1,\n",
    "                     padding=0,\n",
    "                     activation='relu',\n",
    "                     batch_normalize=True,\n",
    "                     dropout=None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param in_channels:\n",
    "    :param out_channels:\n",
    "    :param kernel_size:\n",
    "    :param stride:\n",
    "    :param padding:\n",
    "    :param activation:\n",
    "    :param batch_normalize:\n",
    "    :param dropout:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return get_conv_block(2,\n",
    "                          in_channels,\n",
    "                          out_channels,\n",
    "                          kernel_size,\n",
    "                          stride,\n",
    "                          padding,\n",
    "                          activation,\n",
    "                          batch_normalize,\n",
    "                          dropout)\n",
    "\n",
    "\n",
    "def get_linear_block(in_dim, out_dim, activation='relu', dropout=None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param in_dim:\n",
    "    :param out_dim:\n",
    "    :param activation:\n",
    "    :param dropout:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = nn.Sequential()\n",
    "    linear_layer = nn.Linear(in_dim, out_dim)\n",
    "    model.add_module('linear', linear_layer)\n",
    "\n",
    "    activation_layer = get_activation_layer(activation)\n",
    "    if activation_layer is not None:\n",
    "        model.add_module('activation', activation_layer)\n",
    "\n",
    "    if dropout is not None:\n",
    "        model.add_module('dropout', nn.Dropout(dropout))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_cuda=None):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if use_cuda is None:\n",
    "            self.use_cuda = torch.cuda.is_available()\n",
    "        else:\n",
    "            self.use_cuda = use_cuda\n",
    "\n",
    "        self.conv_0 = get_conv_block2d(3, 6, 5, activation='relu')\n",
    "        self.conv_1 = get_conv_block2d(6, 16, 5, activation='relu')\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.fc1 = get_linear_block(16 * 5 * 5, 120, activation='relu', dropout=0.5)\n",
    "        self.fc2 = get_linear_block(120, 84, activation='relu', dropout=0.5)\n",
    "        self.fc3 = get_linear_block(84, 10, activation=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = self.pool(self.conv_0(x))\n",
    "        x = self.pool(self.conv_1(x))\n",
    "        x = x.reshape(-1, 16 * 5 * 5)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(prediction, label):\n",
    "        \"\"\"\n",
    "\n",
    "        :param prediction:\n",
    "        :param label:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return nn.CrossEntropyLoss()(prediction, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/CIFAR10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose(\n",
    "    \n",
    "    [torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomCrop(size=[32,32], padding=4),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.49140089750289917, 0.4821591377258301, 0.4465310275554657),\n",
    "                                      (0.24702748656272888, 0.24348321557044983, 0.26158758997917175))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = torchvision.transforms.Compose(\n",
    "    \n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.49140089750289917, 0.4821591377258301, 0.4465310275554657),\n",
    "                                      (0.24702748656272888, 0.24348321557044983, 0.26158758997917175))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root, transform=train_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(root, train=False, transform=test_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt, valid_dt = data.random_split(train_dataset, (40000, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_schedules(batch_num, initial_lr, warmup_batchs, total_batchs, decrease_schedules):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if batch_num < warmup_batchs:\n",
    "        lr = initial_lr * (batch_num+1)/warmup_batchs\n",
    "    else:\n",
    "        num = batch_num - warmup_batchs + 1\n",
    "        lr = 0.5 * (1 + math.cos(math.pi * (num / total_batchs))) * initial_lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = net.use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = net.use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "visualizer = visualize.Visualizer('Net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-25 16:35:17.836 | INFO     | __main__:<module>:24 - epoch num: 0, loss: 11.808576226234436, val_precision: 0.6262799501419067, test_precision: 0.6460999250411987, learning_rate: 0.001, time: 28.800416946411133\n",
      "2019-06-25 16:35:46.681 | INFO     | __main__:<module>:24 - epoch num: 1, loss: 11.7473863363266, val_precision: 0.6279200315475464, test_precision: 0.6483999490737915, learning_rate: 0.001, time: 28.792062282562256\n",
      "2019-06-25 16:36:15.485 | INFO     | __main__:<module>:24 - epoch num: 2, loss: 11.709244847297668, val_precision: 0.6262999773025513, test_precision: 0.6442999839782715, learning_rate: 0.001, time: 28.75298023223877\n",
      "2019-06-25 16:36:44.176 | INFO     | __main__:<module>:24 - epoch num: 3, loss: 11.785438537597656, val_precision: 0.629040002822876, test_precision: 0.6504999995231628, learning_rate: 0.001, time: 28.639344215393066\n",
      "2019-06-25 16:37:12.924 | INFO     | __main__:<module>:24 - epoch num: 4, loss: 11.76634693145752, val_precision: 0.6271799802780151, test_precision: 0.6510000228881836, learning_rate: 0.001, time: 28.687578678131104\n",
      "2019-06-25 16:37:41.703 | INFO     | __main__:<module>:24 - epoch num: 5, loss: 11.721476554870605, val_precision: 0.6272000074386597, test_precision: 0.6474000215530396, learning_rate: 0.001, time: 28.726627111434937\n",
      "2019-06-25 16:38:10.486 | INFO     | __main__:<module>:24 - epoch num: 6, loss: 11.728075385093689, val_precision: 0.6321600079536438, test_precision: 0.6490000486373901, learning_rate: 0.001, time: 28.731299877166748\n",
      "2019-06-25 16:38:39.183 | INFO     | __main__:<module>:24 - epoch num: 7, loss: 11.688774585723877, val_precision: 0.6249199509620667, test_precision: 0.6425999999046326, learning_rate: 0.001, time: 28.64489245414734\n",
      "2019-06-25 16:39:07.945 | INFO     | __main__:<module>:24 - epoch num: 8, loss: 11.673940777778625, val_precision: 0.6302200555801392, test_precision: 0.6521999835968018, learning_rate: 0.001, time: 28.711475610733032\n",
      "2019-06-25 16:39:36.626 | INFO     | __main__:<module>:24 - epoch num: 9, loss: 11.62282145023346, val_precision: 0.6270599961280823, test_precision: 0.6521000266075134, learning_rate: 0.001, time: 28.621304988861084\n",
      "2019-06-25 16:40:05.376 | INFO     | __main__:<module>:24 - epoch num: 10, loss: 11.692601680755615, val_precision: 0.6262199878692627, test_precision: 0.6448000073432922, learning_rate: 0.001, time: 28.69829249382019\n",
      "2019-06-25 16:40:34.077 | INFO     | __main__:<module>:24 - epoch num: 11, loss: 11.64366865158081, val_precision: 0.6326799988746643, test_precision: 0.6551999449729919, learning_rate: 0.001, time: 28.650871515274048\n",
      "2019-06-25 16:41:02.813 | INFO     | __main__:<module>:24 - epoch num: 12, loss: 11.632660746574402, val_precision: 0.6313000321388245, test_precision: 0.6552000045776367, learning_rate: 0.001, time: 28.684268712997437\n",
      "2019-06-25 16:41:31.533 | INFO     | __main__:<module>:24 - epoch num: 13, loss: 11.661438703536987, val_precision: 0.6309199929237366, test_precision: 0.6499999761581421, learning_rate: 0.001, time: 28.668048858642578\n",
      "2019-06-25 16:42:00.161 | INFO     | __main__:<module>:24 - epoch num: 14, loss: 11.578726530075073, val_precision: 0.6340600252151489, test_precision: 0.6572999358177185, learning_rate: 0.001, time: 28.576925039291382\n",
      "2019-06-25 16:42:28.868 | INFO     | __main__:<module>:24 - epoch num: 15, loss: 11.668527603149414, val_precision: 0.6351200342178345, test_precision: 0.6547999978065491, learning_rate: 0.001, time: 28.65707039833069\n",
      "2019-06-25 16:42:57.586 | INFO     | __main__:<module>:24 - epoch num: 16, loss: 11.60400128364563, val_precision: 0.6341000199317932, test_precision: 0.6517000198364258, learning_rate: 0.001, time: 28.666654348373413\n",
      "2019-06-25 16:43:26.330 | INFO     | __main__:<module>:24 - epoch num: 17, loss: 11.6864173412323, val_precision: 0.6332999467849731, test_precision: 0.6527000069618225, learning_rate: 0.001, time: 28.693304777145386\n",
      "2019-06-25 16:43:54.948 | INFO     | __main__:<module>:24 - epoch num: 18, loss: 11.636173367500305, val_precision: 0.6355599761009216, test_precision: 0.6540001034736633, learning_rate: 0.001, time: 28.56574535369873\n",
      "2019-06-25 16:44:23.729 | INFO     | __main__:<module>:24 - epoch num: 19, loss: 11.60402226448059, val_precision: 0.6323000192642212, test_precision: 0.655299961566925, learning_rate: 0.001, time: 28.730608463287354\n",
      "2019-06-25 16:44:52.169 | INFO     | __main__:<module>:24 - epoch num: 20, loss: 11.60930347442627, val_precision: 0.638759970664978, test_precision: 0.6567000150680542, learning_rate: 0.001, time: 28.387558221817017\n",
      "2019-06-25 16:45:20.620 | INFO     | __main__:<module>:24 - epoch num: 21, loss: 11.52665400505066, val_precision: 0.6376800537109375, test_precision: 0.6557000279426575, learning_rate: 0.001, time: 28.398411750793457\n",
      "2019-06-25 16:45:49.075 | INFO     | __main__:<module>:24 - epoch num: 22, loss: 11.54582142829895, val_precision: 0.6382600665092468, test_precision: 0.6552000045776367, learning_rate: 0.001, time: 28.401965618133545\n",
      "2019-06-25 16:46:17.396 | INFO     | __main__:<module>:24 - epoch num: 23, loss: 11.588732838630676, val_precision: 0.6356599926948547, test_precision: 0.6604000329971313, learning_rate: 0.001, time: 28.269983768463135\n",
      "2019-06-25 16:46:45.920 | INFO     | __main__:<module>:24 - epoch num: 24, loss: 11.56200110912323, val_precision: 0.6378999948501587, test_precision: 0.6571999788284302, learning_rate: 0.001, time: 28.472182512283325\n",
      "2019-06-25 16:47:14.514 | INFO     | __main__:<module>:24 - epoch num: 25, loss: 11.52967894077301, val_precision: 0.6410800218582153, test_precision: 0.6654000282287598, learning_rate: 0.001, time: 28.54377031326294\n",
      "2019-06-25 16:47:43.158 | INFO     | __main__:<module>:24 - epoch num: 26, loss: 11.476283550262451, val_precision: 0.6383199095726013, test_precision: 0.6617000102996826, learning_rate: 0.001, time: 28.591333627700806\n",
      "2019-06-25 16:48:11.679 | INFO     | __main__:<module>:24 - epoch num: 27, loss: 11.537317156791687, val_precision: 0.6393600106239319, test_precision: 0.6585999727249146, learning_rate: 0.001, time: 28.468567848205566\n",
      "2019-06-25 16:48:40.106 | INFO     | __main__:<module>:24 - epoch num: 28, loss: 11.507248163223267, val_precision: 0.6367000341415405, test_precision: 0.6554999947547913, learning_rate: 0.001, time: 28.3734929561615\n",
      "2019-06-25 16:49:08.652 | INFO     | __main__:<module>:24 - epoch num: 29, loss: 11.48978054523468, val_precision: 0.6383000016212463, test_precision: 0.6615000367164612, learning_rate: 0.001, time: 28.4935245513916\n",
      "2019-06-25 16:49:37.085 | INFO     | __main__:<module>:24 - epoch num: 30, loss: 11.562222242355347, val_precision: 0.637499988079071, test_precision: 0.659500002861023, learning_rate: 0.001, time: 28.37987470626831\n",
      "2019-06-25 16:50:05.591 | INFO     | __main__:<module>:24 - epoch num: 31, loss: 11.462625741958618, val_precision: 0.6410800218582153, test_precision: 0.6627999544143677, learning_rate: 0.001, time: 28.45314311981201\n",
      "2019-06-25 16:50:34.044 | INFO     | __main__:<module>:24 - epoch num: 32, loss: 11.470441579818726, val_precision: 0.6406599879264832, test_precision: 0.6583999991416931, learning_rate: 0.001, time: 28.40207839012146\n",
      "2019-06-25 16:51:02.431 | INFO     | __main__:<module>:24 - epoch num: 33, loss: 11.425781726837158, val_precision: 0.6437200307846069, test_precision: 0.6625000238418579, learning_rate: 0.001, time: 28.33428978919983\n",
      "2019-06-25 16:51:30.906 | INFO     | __main__:<module>:24 - epoch num: 34, loss: 11.393774509429932, val_precision: 0.6380799412727356, test_precision: 0.6572999954223633, learning_rate: 0.001, time: 28.42322826385498\n",
      "2019-06-25 16:51:59.394 | INFO     | __main__:<module>:24 - epoch num: 35, loss: 11.437755942344666, val_precision: 0.6429799795150757, test_precision: 0.663100004196167, learning_rate: 0.001, time: 28.435537815093994\n",
      "2019-06-25 16:52:27.831 | INFO     | __main__:<module>:24 - epoch num: 36, loss: 11.394078731536865, val_precision: 0.6424199938774109, test_precision: 0.6636000275611877, learning_rate: 0.001, time: 28.384859800338745\n",
      "2019-06-25 16:52:56.160 | INFO     | __main__:<module>:24 - epoch num: 37, loss: 11.393983483314514, val_precision: 0.6402199864387512, test_precision: 0.6617000102996826, learning_rate: 0.001, time: 28.277562379837036\n",
      "2019-06-25 16:53:24.633 | INFO     | __main__:<module>:24 - epoch num: 38, loss: 11.421191215515137, val_precision: 0.6458200812339783, test_precision: 0.6660999655723572, learning_rate: 0.001, time: 28.421299934387207\n",
      "2019-06-25 16:53:53.053 | INFO     | __main__:<module>:24 - epoch num: 39, loss: 11.342795848846436, val_precision: 0.6441999673843384, test_precision: 0.6654999852180481, learning_rate: 0.001, time: 28.36743927001953\n",
      "2019-06-25 16:54:21.643 | INFO     | __main__:<module>:24 - epoch num: 40, loss: 11.33188259601593, val_precision: 0.6480599641799927, test_precision: 0.6656999588012695, learning_rate: 0.001, time: 28.537179470062256\n",
      "2019-06-25 16:54:50.025 | INFO     | __main__:<module>:24 - epoch num: 41, loss: 11.277108550071716, val_precision: 0.6447800397872925, test_precision: 0.6648000478744507, learning_rate: 0.001, time: 28.332172393798828\n",
      "2019-06-25 16:55:18.581 | INFO     | __main__:<module>:24 - epoch num: 42, loss: 11.371753692626953, val_precision: 0.6447399854660034, test_precision: 0.6671000123023987, learning_rate: 0.001, time: 28.50300407409668\n",
      "2019-06-25 16:55:47.108 | INFO     | __main__:<module>:24 - epoch num: 43, loss: 11.359807133674622, val_precision: 0.6458200216293335, test_precision: 0.6685999631881714, learning_rate: 0.001, time: 28.47414469718933\n",
      "2019-06-25 16:56:15.566 | INFO     | __main__:<module>:24 - epoch num: 44, loss: 11.318098306655884, val_precision: 0.6469199657440186, test_precision: 0.6684999465942383, learning_rate: 0.001, time: 28.405763626098633\n",
      "2019-06-25 16:56:44.107 | INFO     | __main__:<module>:24 - epoch num: 45, loss: 11.255543947219849, val_precision: 0.6450200080871582, test_precision: 0.6643999814987183, learning_rate: 0.001, time: 28.489598989486694\n",
      "2019-06-25 16:57:12.559 | INFO     | __main__:<module>:24 - epoch num: 46, loss: 11.32863199710846, val_precision: 0.6489599943161011, test_precision: 0.6654999852180481, learning_rate: 0.001, time: 28.399283170700073\n",
      "2019-06-25 16:57:40.982 | INFO     | __main__:<module>:24 - epoch num: 47, loss: 11.300228357315063, val_precision: 0.6460599303245544, test_precision: 0.6682999730110168, learning_rate: 0.001, time: 28.371925115585327\n",
      "2019-06-25 16:58:09.399 | INFO     | __main__:<module>:24 - epoch num: 48, loss: 11.296435475349426, val_precision: 0.6496000289916992, test_precision: 0.664900004863739, learning_rate: 0.001, time: 28.36448383331299\n",
      "2019-06-25 16:58:38.023 | INFO     | __main__:<module>:24 - epoch num: 49, loss: 11.255603909492493, val_precision: 0.6492999792098999, test_precision: 0.6713000535964966, learning_rate: 0.001, time: 28.572227954864502\n",
      "2019-06-25 16:59:06.338 | INFO     | __main__:<module>:24 - epoch num: 50, loss: 11.263358473777771, val_precision: 0.6479200124740601, test_precision: 0.6701000332832336, learning_rate: 0.001, time: 28.264363050460815\n",
      "2019-06-25 16:59:34.733 | INFO     | __main__:<module>:24 - epoch num: 51, loss: 11.301112294197083, val_precision: 0.6482999920845032, test_precision: 0.6675999760627747, learning_rate: 0.001, time: 28.341869592666626\n",
      "2019-06-25 17:00:03.141 | INFO     | __main__:<module>:24 - epoch num: 52, loss: 11.23173701763153, val_precision: 0.6528199911117554, test_precision: 0.6703999638557434, learning_rate: 0.001, time: 28.35566020011902\n",
      "2019-06-25 17:00:31.627 | INFO     | __main__:<module>:24 - epoch num: 53, loss: 11.29215657711029, val_precision: 0.6469399929046631, test_precision: 0.6699999570846558, learning_rate: 0.001, time: 28.43319582939148\n",
      "2019-06-25 17:01:00.224 | INFO     | __main__:<module>:24 - epoch num: 54, loss: 11.294127583503723, val_precision: 0.6550399661064148, test_precision: 0.6697999835014343, learning_rate: 0.001, time: 28.544788599014282\n",
      "2019-06-25 17:01:28.770 | INFO     | __main__:<module>:24 - epoch num: 55, loss: 11.280185341835022, val_precision: 0.6502799987792969, test_precision: 0.6694999933242798, learning_rate: 0.001, time: 28.492425680160522\n",
      "2019-06-25 17:01:57.275 | INFO     | __main__:<module>:24 - epoch num: 56, loss: 11.209457993507385, val_precision: 0.6489399671554565, test_precision: 0.6687999963760376, learning_rate: 0.001, time: 28.451349020004272\n",
      "2019-06-25 17:02:25.722 | INFO     | __main__:<module>:24 - epoch num: 57, loss: 11.256116509437561, val_precision: 0.6496800184249878, test_precision: 0.6681999564170837, learning_rate: 0.001, time: 28.39607858657837\n",
      "2019-06-25 17:02:54.224 | INFO     | __main__:<module>:24 - epoch num: 58, loss: 11.249099850654602, val_precision: 0.6502199769020081, test_precision: 0.6687000393867493, learning_rate: 0.001, time: 28.44968032836914\n",
      "2019-06-25 17:03:22.625 | INFO     | __main__:<module>:24 - epoch num: 59, loss: 11.309720039367676, val_precision: 0.6485599875450134, test_precision: 0.6640999913215637, learning_rate: 0.001, time: 28.348906755447388\n",
      "2019-06-25 17:03:51.056 | INFO     | __main__:<module>:24 - epoch num: 60, loss: 11.254580020904541, val_precision: 0.6508199572563171, test_precision: 0.6723999381065369, learning_rate: 0.001, time: 28.378347396850586\n",
      "2019-06-25 17:04:19.624 | INFO     | __main__:<module>:24 - epoch num: 61, loss: 11.178420543670654, val_precision: 0.6495200395584106, test_precision: 0.66920006275177, learning_rate: 0.001, time: 28.51454997062683\n",
      "2019-06-25 17:04:48.256 | INFO     | __main__:<module>:24 - epoch num: 62, loss: 11.22377872467041, val_precision: 0.6447399854660034, test_precision: 0.6669999957084656, learning_rate: 0.001, time: 28.580253839492798\n",
      "2019-06-25 17:05:16.707 | INFO     | __main__:<module>:24 - epoch num: 63, loss: 11.172187209129333, val_precision: 0.6526400446891785, test_precision: 0.6740000247955322, learning_rate: 0.001, time: 28.39712357521057\n",
      "2019-06-25 17:05:45.000 | INFO     | __main__:<module>:24 - epoch num: 64, loss: 11.235669016838074, val_precision: 0.650399923324585, test_precision: 0.6693999767303467, learning_rate: 0.001, time: 28.24219274520874\n",
      "2019-06-25 17:06:13.365 | INFO     | __main__:<module>:24 - epoch num: 65, loss: 11.185622811317444, val_precision: 0.6427599787712097, test_precision: 0.6570999026298523, learning_rate: 0.001, time: 28.312238931655884\n",
      "2019-06-25 17:06:41.838 | INFO     | __main__:<module>:24 - epoch num: 66, loss: 11.237683057785034, val_precision: 0.6512399911880493, test_precision: 0.6660999059677124, learning_rate: 0.001, time: 28.419817686080933\n",
      "2019-06-25 17:07:10.469 | INFO     | __main__:<module>:24 - epoch num: 67, loss: 11.207577109336853, val_precision: 0.6527800559997559, test_precision: 0.6682000160217285, learning_rate: 0.001, time: 28.57834243774414\n",
      "2019-06-25 17:07:38.884 | INFO     | __main__:<module>:24 - epoch num: 68, loss: 11.272376537322998, val_precision: 0.6504999399185181, test_precision: 0.6688000559806824, learning_rate: 0.001, time: 28.361592531204224\n",
      "2019-06-25 17:08:07.380 | INFO     | __main__:<module>:24 - epoch num: 69, loss: 11.103791952133179, val_precision: 0.6517199873924255, test_precision: 0.6743000149726868, learning_rate: 0.001, time: 28.443201541900635\n",
      "2019-06-25 17:08:35.667 | INFO     | __main__:<module>:24 - epoch num: 70, loss: 11.104476690292358, val_precision: 0.6566200256347656, test_precision: 0.6735000610351562, learning_rate: 0.001, time: 28.2328884601593\n",
      "2019-06-25 17:09:04.092 | INFO     | __main__:<module>:24 - epoch num: 71, loss: 11.189586758613586, val_precision: 0.6514399647712708, test_precision: 0.6688999533653259, learning_rate: 0.001, time: 28.37297034263611\n",
      "2019-06-25 17:09:32.700 | INFO     | __main__:<module>:24 - epoch num: 72, loss: 11.093135237693787, val_precision: 0.6532999277114868, test_precision: 0.670699954032898, learning_rate: 0.001, time: 28.554657220840454\n",
      "2019-06-25 17:10:01.100 | INFO     | __main__:<module>:24 - epoch num: 73, loss: 11.124389052391052, val_precision: 0.6569600105285645, test_precision: 0.6753999590873718, learning_rate: 0.001, time: 28.346486806869507\n",
      "2019-06-25 17:10:29.589 | INFO     | __main__:<module>:24 - epoch num: 74, loss: 11.173927545547485, val_precision: 0.6517599821090698, test_precision: 0.6721999645233154, learning_rate: 0.001, time: 28.436243295669556\n",
      "2019-06-25 17:10:58.037 | INFO     | __main__:<module>:24 - epoch num: 75, loss: 11.184983253479004, val_precision: 0.6477800607681274, test_precision: 0.6654999256134033, learning_rate: 0.001, time: 28.395963430404663\n",
      "2019-06-25 17:11:26.489 | INFO     | __main__:<module>:24 - epoch num: 76, loss: 11.26912522315979, val_precision: 0.65093994140625, test_precision: 0.6737000346183777, learning_rate: 0.001, time: 28.398674488067627\n",
      "2019-06-25 17:11:54.789 | INFO     | __main__:<module>:24 - epoch num: 77, loss: 11.2474924325943, val_precision: 0.6499000787734985, test_precision: 0.6674000024795532, learning_rate: 0.001, time: 28.246721029281616\n",
      "2019-06-25 17:12:23.222 | INFO     | __main__:<module>:24 - epoch num: 78, loss: 11.143355131149292, val_precision: 0.650879979133606, test_precision: 0.6715999841690063, learning_rate: 0.001, time: 28.37820529937744\n",
      "2019-06-25 17:12:51.771 | INFO     | __main__:<module>:24 - epoch num: 79, loss: 11.154935002326965, val_precision: 0.6565600633621216, test_precision: 0.6718000173568726, learning_rate: 0.001, time: 28.49559211730957\n",
      "2019-06-25 17:13:20.319 | INFO     | __main__:<module>:24 - epoch num: 80, loss: 11.123978734016418, val_precision: 0.6514999866485596, test_precision: 0.6713000535964966, learning_rate: 0.001, time: 28.494883060455322\n",
      "2019-06-25 17:13:48.769 | INFO     | __main__:<module>:24 - epoch num: 81, loss: 11.081149697303772, val_precision: 0.6571400165557861, test_precision: 0.6748999953269958, learning_rate: 0.001, time: 28.398530960083008\n",
      "2019-06-25 17:14:17.291 | INFO     | __main__:<module>:24 - epoch num: 82, loss: 11.179386615753174, val_precision: 0.6581000089645386, test_precision: 0.6736999750137329, learning_rate: 0.001, time: 28.469199895858765\n",
      "2019-06-25 17:14:45.909 | INFO     | __main__:<module>:24 - epoch num: 83, loss: 11.146685600280762, val_precision: 0.655239999294281, test_precision: 0.6759999990463257, learning_rate: 0.001, time: 28.564473867416382\n",
      "2019-06-25 17:15:14.525 | INFO     | __main__:<module>:24 - epoch num: 84, loss: 11.137641072273254, val_precision: 0.6567999720573425, test_precision: 0.6764000058174133, learning_rate: 0.001, time: 28.562119007110596\n",
      "2019-06-25 17:15:43.127 | INFO     | __main__:<module>:24 - epoch num: 85, loss: 11.142431497573853, val_precision: 0.658560037612915, test_precision: 0.6785999536514282, learning_rate: 0.001, time: 28.54877257347107\n",
      "2019-06-25 17:16:11.552 | INFO     | __main__:<module>:24 - epoch num: 86, loss: 11.11168086528778, val_precision: 0.6543800234794617, test_precision: 0.668999969959259, learning_rate: 0.001, time: 28.373103857040405\n",
      "2019-06-25 17:16:40.112 | INFO     | __main__:<module>:24 - epoch num: 87, loss: 11.082756996154785, val_precision: 0.6578199863433838, test_precision: 0.6694999933242798, learning_rate: 0.001, time: 28.50626826286316\n",
      "2019-06-25 17:17:08.673 | INFO     | __main__:<module>:24 - epoch num: 88, loss: 11.000150918960571, val_precision: 0.6594399809837341, test_precision: 0.6780999898910522, learning_rate: 0.001, time: 28.509310245513916\n",
      "2019-06-25 17:17:37.191 | INFO     | __main__:<module>:24 - epoch num: 89, loss: 11.110538721084595, val_precision: 0.6585400700569153, test_precision: 0.6780999898910522, learning_rate: 0.001, time: 28.464545488357544\n",
      "2019-06-25 17:18:05.638 | INFO     | __main__:<module>:24 - epoch num: 90, loss: 11.078733801841736, val_precision: 0.6543399691581726, test_precision: 0.6739000082015991, learning_rate: 0.001, time: 28.394590377807617\n",
      "2019-06-25 17:18:34.130 | INFO     | __main__:<module>:24 - epoch num: 91, loss: 11.143932223320007, val_precision: 0.6575799584388733, test_precision: 0.6793999671936035, learning_rate: 0.001, time: 28.43954849243164\n",
      "2019-06-25 17:19:02.639 | INFO     | __main__:<module>:24 - epoch num: 92, loss: 11.01646113395691, val_precision: 0.658079981803894, test_precision: 0.6779999732971191, learning_rate: 0.001, time: 28.455445528030396\n",
      "2019-06-25 17:19:31.115 | INFO     | __main__:<module>:24 - epoch num: 93, loss: 10.976105093955994, val_precision: 0.6541399955749512, test_precision: 0.6780999898910522, learning_rate: 0.001, time: 28.425143480300903\n",
      "2019-06-25 17:19:59.699 | INFO     | __main__:<module>:24 - epoch num: 94, loss: 11.098891615867615, val_precision: 0.6638399958610535, test_precision: 0.6770000457763672, learning_rate: 0.001, time: 28.532073736190796\n",
      "2019-06-25 17:20:28.160 | INFO     | __main__:<module>:24 - epoch num: 95, loss: 11.00881838798523, val_precision: 0.6588000059127808, test_precision: 0.6771999597549438, learning_rate: 0.001, time: 28.407333850860596\n",
      "2019-06-25 17:20:56.721 | INFO     | __main__:<module>:24 - epoch num: 96, loss: 11.13437819480896, val_precision: 0.6581999659538269, test_precision: 0.6773000359535217, learning_rate: 0.001, time: 28.509072065353394\n",
      "2019-06-25 17:21:25.237 | INFO     | __main__:<module>:24 - epoch num: 97, loss: 11.055813312530518, val_precision: 0.6546600461006165, test_precision: 0.675599992275238, learning_rate: 0.001, time: 28.461514472961426\n",
      "2019-06-25 17:21:53.655 | INFO     | __main__:<module>:24 - epoch num: 98, loss: 11.085136532783508, val_precision: 0.6618800163269043, test_precision: 0.6756001114845276, learning_rate: 0.001, time: 28.364028692245483\n",
      "2019-06-25 17:22:22.206 | INFO     | __main__:<module>:24 - epoch num: 99, loss: 11.050772666931152, val_precision: 0.6589599847793579, test_precision: 0.6773999929428101, learning_rate: 0.001, time: 28.498111963272095\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    start_time = time.time()\n",
    "    net.train()\n",
    "    train_dt, valid_dt = data.random_split(train_dataset, (40000, 10000))\n",
    "    train_data_iter = data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n",
    "    running_loss = 0.0\n",
    "    for i, (train_data, label) in enumerate(train_data_iter):\n",
    "        \n",
    "        \n",
    "        if use_cuda:\n",
    "            train_data = train_data.cuda()\n",
    "            label = label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        prediction = net(train_data)\n",
    "        loss = net.loss(prediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    valid_train_res, valid_ap = validate(net, train_dataset, batch_size, num_class=10)\n",
    "    valid_test_res, test_ap = validate(net, test_dataset, batch_size, num_class=10)\n",
    "    loss_dct = {'loss': running_loss}\n",
    "    val_precision = valid_train_res['map']\n",
    "    val_ap_dct = {classes[i]: v for i, v in enumerate(valid_ap)}\n",
    "    test_precision = valid_test_res['map']\n",
    "    logger.info(f'epoch num: {e}, loss: {running_loss}, val_precision: {val_precision}, test_precision: {test_precision}, learning_rate: {learning_rate}, time: {time.time() - start_time}')\n",
    "    visualizer.plot(loss_dct)\n",
    "    visualizer.plot({'val_precision': val_precision})\n",
    "    visualizer.plot(val_ap_dct)\n",
    "    visualizer.plot({'test_precision': test_precision})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'audio_net_002.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 529.4704940319061,\n",
       " 'val_precision': 0.78054,\n",
       " 'test_precision': 0.6408,\n",
       " 'learning_rate': 0.01,\n",
       " 'time': 19.557708978652954}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'loss': 529.4704940319061, 'val_precision': 0.78054, 'test_precision': 0.6408, 'learning_rate': 0.01, 'time': 19.557708978652954}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
