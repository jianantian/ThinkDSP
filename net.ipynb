{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.add('train_audionet.log', level='INFO', colorize=True, format=\"<green>{time}</green> <level>{message}</level>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    __slots__ = ('root', 'train_fname', 'epoch', 'batch_size', 'input_length', \n",
    "                 'save_interval', 'val_interval', 'log_interval', 'lr', 'lr_decay', \n",
    "                 'lr_decay_period', 'lr_decay_epoch', 'wd')\n",
    "\n",
    "    def __init__(self, dct):\n",
    "        \"\"\"\n",
    "\n",
    "        :param dct:\n",
    "        \"\"\"\n",
    "        for k in self.__slots__:\n",
    "            v = dct.get(k, None)\n",
    "            if k in {\"train_root\", \"val_root\", \"trainval_root\"}:\n",
    "                v = Path(v)\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(config_path):\n",
    "    \"\"\"\n",
    "\n",
    "    :param config_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with open(config_path, 'r') as fr:\n",
    "        dct = json.load(fr)\n",
    "    return Config(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedLayer(nn.Sequential):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsample_layer(out_channels, kernel_size, batch_normalize=True):\n",
    "    model = NamedLayer(f'subsample')\n",
    "    layer = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size=kernel_size, stride=kernel_size),\n",
    "                         nn.LeakyReLU(0.1),\n",
    "                         nn.BatchNorm1d(out_channels))\n",
    "    model.add_module('subsample', layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(index, in_channels, out_channels, kernel_size, num=2, batch_normalize=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    model = NamedLayer(f'convolutional_{index}')\n",
    "    layer = nn.Sequential(nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=1),\n",
    "                     nn.LeakyReLU(0.1),\n",
    "                     nn.BatchNorm1d(out_channels),\n",
    "                         nn.MaxPool1d(kernel_size))\n",
    "    model.add_module(f'convolutional', layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softmax_layer(in_channels, num_class):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    model = NamedLayer('softmax')\n",
    "    linear_layer = nn.Linear(in_channels, num_class)\n",
    "    model.add_module(f'linear', linear_layer)\n",
    "    softmax_layer = nn.Softmax(dim=1)\n",
    "    model.add_module(f'softmax', softmax_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioNet(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_length,\n",
    "                 name_tuple,\n",
    "                 use_cuda=torch.cuda.is_available()):\n",
    "        super().__init__()\n",
    "        self.input_length = input_length\n",
    "        self.name_tuple = name_tuple\n",
    "        self.num_class = len(name_tuple)\n",
    "        self.use_cuda=use_cuda\n",
    "        self._init()\n",
    "        \n",
    "    def _init(self):\n",
    "        subsample_block = get_subsample_layer(128, kernel_size=3)\n",
    "#         self.add_module('subsample_block', subsample_block)\n",
    "        self.subsample_layer = subsample_block\n",
    "    \n",
    "        conv_block = NamedLayer('convolution')\n",
    "        \n",
    "        base_index = 0\n",
    "        for i in range(2):\n",
    "            sub_conv_block = get_block(i + base_index, in_channels=128, out_channels=128, kernel_size=3)\n",
    "            conv_block.add_module(f'conv_block_{i+base_index}', sub_conv_block)\n",
    "        \n",
    "        base_index += 2\n",
    "\n",
    "        sub_conv_block = get_block(base_index, in_channels=128, out_channels=256, kernel_size=3)\n",
    "        conv_block.add_module('conv_block_2', sub_conv_block)\n",
    "        base_index += 1\n",
    "        \n",
    "        for i in range(5):\n",
    "            sub_conv_block = get_block(i + base_index, in_channels=256, out_channels=256, kernel_size=3)\n",
    "            conv_block.add_module(f'conv_block_{i+base_index}', sub_conv_block)\n",
    "        base_index += 5\n",
    "                                  \n",
    "        sub_conv_block = get_block(base_index, in_channels=256, out_channels=512, kernel_size=3)\n",
    "        conv_block.add_module(f'conv_block_{base_index}', sub_conv_block)\n",
    "        \n",
    "        end_conv_block = nn.Sequential(nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.LeakyReLU(0.1),\n",
    "                                        nn.Dropout(0.5))\n",
    "        conv_block.add_module(f'end_conv_block', end_conv_block)\n",
    "        \n",
    "        # self.add_module('convolution', conv_block)\n",
    "        self.convolution_layer = conv_block\n",
    "        \n",
    "        softmax_block = get_softmax_layer(512, self.num_class)\n",
    "        # self.add_module('softmax_block', softmax_block)\n",
    "        self.softmax_layer = softmax_block\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        x = torch.unsqueeze(x, dim=1)\n",
    "        x = self.subsample_layer(x)\n",
    "        x = self.convolution_layer(x)\n",
    "        \n",
    "        b, c, l = x.shape\n",
    "        size = c * l\n",
    "        x = x.reshape((b, size, ))\n",
    "        \n",
    "        x = self.softmax_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        return loss(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/data/FSDKaggle2018/FSDKaggle2018.audio_train')\n",
    "train_fname = Path('/data/FSDKaggle2018/FSDKaggle2018.meta/train_post_competition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, label_dct = utils.get_dataset_meta(train_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-24 09:55:14.376 | INFO     | utils:get_test_data:60 - Reading from /data/FSDKaggle2018/FSDKaggle2018.meta/train_validate.csv\n"
     ]
    }
   ],
   "source": [
    "full_df = utils.get_test_data(train_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = full_df[full_df.test == False]\n",
    "train_df.index = range(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = full_df[full_df.test == True]\n",
    "test_df.index = range(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = parse_config('config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = config.input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = utils.Dataset(root, train_df, input_length, num_class=num_class, label_dct=label_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = data.DataLoader(train_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AudioNet(input_length=input_length, name_tuple=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = config.lr\n",
    "weight_decay = config.wd\n",
    "\n",
    "val_interval = config.val_interval\n",
    "save_interval = config.save_interval\n",
    "log_interval = config.log_interval\n",
    "\n",
    "lr_decay_epoch = set(config.lr_decay_epoch)\n",
    "lr_decay = config.lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = config.epoch\n",
    "batch_size = config.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = net.use_cuda\n",
    "if use_cuda:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "visualizer = visualize.Visualizer('AudioNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net,\n",
    "             val_data,\n",
    "             batch_size):\n",
    "    net.eval()\n",
    "\n",
    "    num_class = val_data.num_class\n",
    "\n",
    "    val_data_iter = data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    use_cuda = net.use_cuda\n",
    "\n",
    "    total_num = 0\n",
    "    true_detect_num = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (val_data, label) in enumerate(val_data_iter):\n",
    "            if use_cuda:\n",
    "                val_data = val_data.cuda()\n",
    "                label = label.cuda()\n",
    "            prediction = net(val_data)\n",
    "            _, prediction_label = torch.max(prediction, dim=1)\n",
    "            \n",
    "            total_num += label.shape[0]\n",
    "            true_detect_num += (prediction_label == label).sum().item()\n",
    "            \n",
    "    val_mean_precision = true_detect_num / total_num\n",
    "\n",
    "    validation_res_dct = {'precision': val_mean_precision}\n",
    "    return validation_res_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrevLoss:\n",
    "    def __init__(self):\n",
    "        self.__container = deque([])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.__container)\n",
    "    \n",
    "    def pop(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.__container.popleft()\n",
    "        \n",
    "    def append(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        container = self.__container\n",
    "        while len(container) >= 3:\n",
    "            container.pop()\n",
    "        container.append(x)\n",
    "        self.__container = container\n",
    "    \n",
    "    def value(self):\n",
    "        return min(self.__container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-24 09:56:26.800 | INFO     | __main__:<module>:36 - epoch num: 0, loss: 497.3456733226776, val_precision: 0.11191588785046729, test_precision: 0.11938663745892661, learning_rate: 0.01, time: 60.063957929611206\n",
      "2019-06-24 09:57:27.553 | INFO     | __main__:<module>:36 - epoch num: 1, loss: 493.07331919670105, val_precision: 0.0838785046728972, test_precision: 0.09419496166484119, learning_rate: 0.01, time: 60.73784136772156\n",
      "2019-06-24 09:58:29.186 | INFO     | __main__:<module>:36 - epoch num: 2, loss: 488.3221912384033, val_precision: 0.10420560747663551, test_precision: 0.12595837897042717, learning_rate: 0.01, time: 61.61560893058777\n",
      "2019-06-24 09:59:31.091 | INFO     | __main__:<module>:36 - epoch num: 3, loss: 486.4327199459076, val_precision: 0.13983644859813085, test_precision: 0.15553121577217963, learning_rate: 0.01, time: 61.88931179046631\n",
      "2019-06-24 10:00:33.374 | INFO     | __main__:<module>:36 - epoch num: 4, loss: 482.39139461517334, val_precision: 0.15455607476635513, test_precision: 0.16976998904709747, learning_rate: 0.01, time: 62.26866698265076\n",
      "2019-06-24 10:01:35.417 | INFO     | __main__:<module>:36 - epoch num: 5, loss: 479.71869254112244, val_precision: 0.16658878504672897, test_precision: 0.18072289156626506, learning_rate: 0.01, time: 62.02776002883911\n",
      "2019-06-24 10:02:37.328 | INFO     | __main__:<module>:36 - epoch num: 6, loss: 479.1172058582306, val_precision: 0.16950934579439253, test_precision: 0.18181818181818182, learning_rate: 0.01, time: 61.89657735824585\n",
      "2019-06-24 10:03:39.334 | INFO     | __main__:<module>:36 - epoch num: 7, loss: 477.43198442459106, val_precision: 0.19123831775700934, test_precision: 0.20810514786418402, learning_rate: 0.01, time: 61.9902663230896\n",
      "2019-06-24 10:04:41.296 | INFO     | __main__:<module>:36 - epoch num: 8, loss: 475.31824493408203, val_precision: 0.18785046728971963, test_precision: 0.21467688937568455, learning_rate: 0.01, time: 61.946481466293335\n",
      "2019-06-24 10:05:43.536 | INFO     | __main__:<module>:36 - epoch num: 9, loss: 474.42533659935, val_precision: 0.21039719626168224, test_precision: 0.22562979189485213, learning_rate: 0.01, time: 62.225534200668335\n",
      "2019-06-24 10:06:45.856 | INFO     | __main__:<module>:36 - epoch num: 10, loss: 473.44642162323, val_precision: 0.22009345794392524, test_precision: 0.23767798466593648, learning_rate: 0.01, time: 62.30435252189636\n",
      "2019-06-24 10:07:48.404 | INFO     | __main__:<module>:36 - epoch num: 11, loss: 471.31348180770874, val_precision: 0.26238317757009344, test_precision: 0.2727272727272727, learning_rate: 0.01, time: 62.53465175628662\n",
      "2019-06-24 10:08:50.782 | INFO     | __main__:<module>:36 - epoch num: 12, loss: 469.33728194236755, val_precision: 0.2731308411214953, test_precision: 0.28039430449069, learning_rate: 0.01, time: 62.36282253265381\n",
      "2019-06-24 10:09:53.155 | INFO     | __main__:<module>:36 - epoch num: 13, loss: 467.5444691181183, val_precision: 0.27932242990654205, test_precision: 0.2836801752464403, learning_rate: 0.01, time: 62.35829830169678\n",
      "2019-06-24 10:10:55.566 | INFO     | __main__:<module>:36 - epoch num: 14, loss: 467.03788018226624, val_precision: 0.26880841121495325, test_precision: 0.2858707557502738, learning_rate: 0.01, time: 62.396910429000854\n",
      "2019-06-24 10:11:57.973 | INFO     | __main__:<module>:36 - epoch num: 15, loss: 465.54577565193176, val_precision: 0.26121495327102806, test_precision: 0.2683461117196057, learning_rate: 0.01, time: 62.39219331741333\n",
      "2019-06-24 10:13:00.389 | INFO     | __main__:<module>:36 - epoch num: 16, loss: 465.8776202201843, val_precision: 0.2564252336448598, test_precision: 0.2606790799561884, learning_rate: 0.01, time: 62.40069103240967\n",
      "2019-06-24 10:14:02.798 | INFO     | __main__:<module>:36 - epoch num: 17, loss: 465.00890588760376, val_precision: 0.2836448598130841, test_precision: 0.28696604600219056, learning_rate: 0.01, time: 62.39444708824158\n",
      "2019-06-24 10:15:05.167 | INFO     | __main__:<module>:36 - epoch num: 18, loss: 463.24677538871765, val_precision: 0.25455607476635517, test_precision: 0.2606790799561884, learning_rate: 0.01, time: 62.35469365119934\n",
      "2019-06-24 10:16:07.662 | INFO     | __main__:<module>:36 - epoch num: 19, loss: 462.58005023002625, val_precision: 0.3130841121495327, test_precision: 0.3132530120481928, learning_rate: 0.01, time: 62.479247093200684\n",
      "2019-06-24 10:17:10.097 | INFO     | __main__:<module>:36 - epoch num: 20, loss: 461.8829171657562, val_precision: 0.30011682242990656, test_precision: 0.29901423877327493, learning_rate: 0.01, time: 62.42128825187683\n",
      "2019-06-24 10:18:12.515 | INFO     | __main__:<module>:36 - epoch num: 21, loss: 461.19641041755676, val_precision: 0.3008177570093458, test_precision: 0.307776560788609, learning_rate: 0.01, time: 62.40364146232605\n",
      "2019-06-24 10:19:15.021 | INFO     | __main__:<module>:36 - epoch num: 22, loss: 460.30323028564453, val_precision: 0.273714953271028, test_precision: 0.27491785323110624, learning_rate: 0.01, time: 62.49149703979492\n",
      "2019-06-24 10:20:17.568 | INFO     | __main__:<module>:36 - epoch num: 23, loss: 459.30001425743103, val_precision: 0.3230140186915888, test_precision: 0.3176341730558598, learning_rate: 0.01, time: 62.53136658668518\n",
      "2019-06-24 10:21:20.073 | INFO     | __main__:<module>:36 - epoch num: 24, loss: 458.1491401195526, val_precision: 0.33060747663551404, test_precision: 0.3176341730558598, learning_rate: 0.01, time: 62.49079179763794\n",
      "2019-06-24 10:22:22.527 | INFO     | __main__:<module>:36 - epoch num: 25, loss: 457.5493896007538, val_precision: 0.34567757009345795, test_precision: 0.3209200438116101, learning_rate: 0.01, time: 62.43989372253418\n",
      "2019-06-24 10:23:25.030 | INFO     | __main__:<module>:36 - epoch num: 26, loss: 455.9752080440521, val_precision: 0.33598130841121493, test_precision: 0.3066812705366922, learning_rate: 0.01, time: 62.48762845993042\n",
      "2019-06-24 10:24:27.452 | INFO     | __main__:<module>:36 - epoch num: 27, loss: 455.0868148803711, val_precision: 0.3535046728971963, test_precision: 0.3548740416210296, learning_rate: 0.01, time: 62.407673597335815\n",
      "2019-06-24 10:25:29.850 | INFO     | __main__:<module>:36 - epoch num: 28, loss: 453.869087934494, val_precision: 0.3697429906542056, test_precision: 0.3515881708652793, learning_rate: 0.01, time: 62.383973836898804\n",
      "2019-06-24 10:26:32.246 | INFO     | __main__:<module>:36 - epoch num: 29, loss: 454.16315031051636, val_precision: 0.29007009345794393, test_precision: 0.2946330777656079, learning_rate: 0.01, time: 62.375921964645386\n",
      "2019-06-24 10:27:34.597 | INFO     | __main__:<module>:36 - epoch num: 30, loss: 454.4931824207306, val_precision: 0.3582943925233645, test_precision: 0.35815991237677985, learning_rate: 0.01, time: 62.335941791534424\n",
      "2019-06-24 10:28:36.562 | INFO     | __main__:<module>:36 - epoch num: 31, loss: 453.3500018119812, val_precision: 0.37348130841121496, test_precision: 0.3603504928806134, learning_rate: 0.01, time: 61.95047044754028\n",
      "2019-06-24 10:29:38.539 | INFO     | __main__:<module>:36 - epoch num: 32, loss: 453.8246228694916, val_precision: 0.3530373831775701, test_precision: 0.3362541073384447, learning_rate: 0.01, time: 61.96218156814575\n",
      "2019-06-24 10:30:40.547 | INFO     | __main__:<module>:36 - epoch num: 33, loss: 452.939391374588, val_precision: 0.36752336448598133, test_precision: 0.35706462212486306, learning_rate: 0.01, time: 61.992971897125244\n",
      "2019-06-24 10:31:42.670 | INFO     | __main__:<module>:36 - epoch num: 34, loss: 452.70822978019714, val_precision: 0.37231308411214953, test_precision: 0.35706462212486306, learning_rate: 0.01, time: 62.109342098236084\n",
      "2019-06-24 10:32:44.778 | INFO     | __main__:<module>:36 - epoch num: 35, loss: 452.61341309547424, val_precision: 0.3802570093457944, test_precision: 0.348302300109529, learning_rate: 0.01, time: 62.0926616191864\n",
      "2019-06-24 10:33:46.906 | INFO     | __main__:<module>:36 - epoch num: 36, loss: 451.85551047325134, val_precision: 0.35665887850467287, test_precision: 0.35049288061336253, learning_rate: 0.01, time: 62.1134557723999\n",
      "2019-06-24 10:34:49.456 | INFO     | __main__:<module>:36 - epoch num: 37, loss: 451.4278657436371, val_precision: 0.35899532710280374, test_precision: 0.34501642935377874, learning_rate: 0.01, time: 62.53705048561096\n",
      "2019-06-24 10:35:51.942 | INFO     | __main__:<module>:36 - epoch num: 38, loss: 450.72707200050354, val_precision: 0.3820093457943925, test_precision: 0.3669222343921139, learning_rate: 0.01, time: 62.47080969810486\n",
      "2019-06-24 10:36:54.431 | INFO     | __main__:<module>:36 - epoch num: 39, loss: 450.6956992149353, val_precision: 0.38317757009345793, test_precision: 0.36363636363636365, learning_rate: 0.01, time: 62.47537326812744\n",
      "2019-06-24 10:37:56.661 | INFO     | __main__:<module>:36 - epoch num: 40, loss: 449.7263698577881, val_precision: 0.41682242990654206, test_precision: 0.3932092004381161, learning_rate: 0.01, time: 62.21567749977112\n",
      "2019-06-24 10:38:59.237 | INFO     | __main__:<module>:36 - epoch num: 41, loss: 448.9060306549072, val_precision: 0.4088785046728972, test_precision: 0.38663745892661555, learning_rate: 0.01, time: 62.561509132385254\n",
      "2019-06-24 10:40:01.656 | INFO     | __main__:<module>:36 - epoch num: 42, loss: 448.0196006298065, val_precision: 0.4269859813084112, test_precision: 0.4173055859802848, learning_rate: 0.01, time: 62.40384531021118\n",
      "2019-06-24 10:41:04.170 | INFO     | __main__:<module>:36 - epoch num: 43, loss: 447.76340794563293, val_precision: 0.4244158878504673, test_precision: 0.4008762322015334, learning_rate: 0.01, time: 62.499879598617554\n",
      "2019-06-24 10:42:06.708 | INFO     | __main__:<module>:36 - epoch num: 44, loss: 446.917183637619, val_precision: 0.41950934579439253, test_precision: 0.3877327491785323, learning_rate: 0.01, time: 62.523433208465576\n",
      "2019-06-24 10:43:09.133 | INFO     | __main__:<module>:36 - epoch num: 45, loss: 447.66600584983826, val_precision: 0.3852803738317757, test_precision: 0.3603504928806134, learning_rate: 0.01, time: 62.409738063812256\n",
      "2019-06-24 10:44:11.252 | INFO     | __main__:<module>:36 - epoch num: 46, loss: 447.03893208503723, val_precision: 0.40572429906542057, test_precision: 0.37677984665936476, learning_rate: 0.01, time: 62.10541319847107\n",
      "2019-06-24 10:45:13.343 | INFO     | __main__:<module>:36 - epoch num: 47, loss: 447.134388923645, val_precision: 0.40350467289719627, test_precision: 0.3833515881708653, learning_rate: 0.01, time: 62.07652282714844\n",
      "2019-06-24 10:46:15.368 | INFO     | __main__:<module>:36 - epoch num: 48, loss: 447.953533411026, val_precision: 0.4241822429906542, test_precision: 0.40525739320920046, learning_rate: 0.01, time: 62.00954461097717\n",
      "2019-06-24 10:47:17.474 | INFO     | __main__:<module>:36 - epoch num: 49, loss: 447.13372230529785, val_precision: 0.40852803738317756, test_precision: 0.38116100766703176, learning_rate: 0.01, time: 62.09010457992554\n",
      "2019-06-24 10:48:19.450 | INFO     | __main__:<module>:36 - epoch num: 50, loss: 446.41965556144714, val_precision: 0.41962616822429905, test_precision: 0.40416210295728366, learning_rate: 0.01, time: 61.96260190010071\n",
      "2019-06-24 10:49:21.590 | INFO     | __main__:<module>:36 - epoch num: 51, loss: 446.70721411705017, val_precision: 0.42348130841121495, test_precision: 0.40306681270536693, learning_rate: 0.01, time: 62.12431979179382\n",
      "2019-06-24 10:50:23.739 | INFO     | __main__:<module>:36 - epoch num: 52, loss: 446.39302802085876, val_precision: 0.4371495327102804, test_precision: 0.4019715224534502, learning_rate: 0.01, time: 62.13477325439453\n",
      "2019-06-24 10:51:25.916 | INFO     | __main__:<module>:36 - epoch num: 53, loss: 446.69474482536316, val_precision: 0.4203271028037383, test_precision: 0.39211391018619934, learning_rate: 0.01, time: 62.16271185874939\n",
      "2019-06-24 10:52:28.004 | INFO     | __main__:<module>:36 - epoch num: 54, loss: 446.62111830711365, val_precision: 0.4371495327102804, test_precision: 0.4063526834611172, learning_rate: 0.01, time: 62.07324266433716\n",
      "2019-06-24 10:53:30.359 | INFO     | __main__:<module>:36 - epoch num: 55, loss: 445.7753393650055, val_precision: 0.4350467289719626, test_precision: 0.39759036144578314, learning_rate: 0.01, time: 62.34020781517029\n",
      "2019-06-24 10:54:32.940 | INFO     | __main__:<module>:36 - epoch num: 56, loss: 445.51530718803406, val_precision: 0.41869158878504675, test_precision: 0.3910186199342826, learning_rate: 0.01, time: 62.5661883354187\n",
      "2019-06-24 10:55:35.406 | INFO     | __main__:<module>:36 - epoch num: 57, loss: 445.956862449646, val_precision: 0.42429906542056073, test_precision: 0.40306681270536693, learning_rate: 0.01, time: 62.45251274108887\n",
      "2019-06-24 10:56:37.769 | INFO     | __main__:<module>:36 - epoch num: 58, loss: 446.01606917381287, val_precision: 0.44042056074766356, test_precision: 0.40744797371303393, learning_rate: 0.01, time: 62.348456382751465\n",
      "2019-06-24 10:57:40.320 | INFO     | __main__:<module>:36 - epoch num: 59, loss: 445.46142506599426, val_precision: 0.4375, test_precision: 0.4129244249726177, learning_rate: 0.01, time: 62.53618550300598\n",
      "2019-06-24 10:58:42.689 | INFO     | __main__:<module>:36 - epoch num: 60, loss: 444.7916488647461, val_precision: 0.4139018691588785, test_precision: 0.38116100766703176, learning_rate: 0.01, time: 62.35417699813843\n",
      "2019-06-24 10:59:44.759 | INFO     | __main__:<module>:36 - epoch num: 61, loss: 445.0599946975708, val_precision: 0.4136682242990654, test_precision: 0.38663745892661555, learning_rate: 0.01, time: 62.05566096305847\n",
      "2019-06-24 11:00:46.791 | INFO     | __main__:<module>:36 - epoch num: 62, loss: 445.30871629714966, val_precision: 0.42149532710280374, test_precision: 0.39211391018619934, learning_rate: 0.01, time: 62.018311738967896\n",
      "2019-06-24 11:01:49.058 | INFO     | __main__:<module>:36 - epoch num: 63, loss: 445.0637421607971, val_precision: 0.4199766355140187, test_precision: 0.380065717415115, learning_rate: 0.01, time: 62.25257086753845\n",
      "2019-06-24 11:02:51.137 | INFO     | __main__:<module>:36 - epoch num: 64, loss: 444.45935463905334, val_precision: 0.44684579439252337, test_precision: 0.41511500547645125, learning_rate: 0.01, time: 62.06387543678284\n",
      "2019-06-24 11:03:53.162 | INFO     | __main__:<module>:36 - epoch num: 65, loss: 444.03118205070496, val_precision: 0.4505841121495327, test_precision: 0.4194961664841183, learning_rate: 0.01, time: 62.01067113876343\n",
      "2019-06-24 11:04:55.331 | INFO     | __main__:<module>:36 - epoch num: 66, loss: 444.2449390888214, val_precision: 0.4391355140186916, test_precision: 0.4129244249726177, learning_rate: 0.01, time: 62.153666973114014\n",
      "2019-06-24 11:05:57.552 | INFO     | __main__:<module>:36 - epoch num: 67, loss: 444.9573519229889, val_precision: 0.40572429906542057, test_precision: 0.384446878422782, learning_rate: 0.01, time: 62.20638298988342\n",
      "2019-06-24 11:06:59.544 | INFO     | __main__:<module>:36 - epoch num: 68, loss: 444.05046939849854, val_precision: 0.4522196261682243, test_precision: 0.41073384446878425, learning_rate: 0.01, time: 61.97792291641235\n",
      "2019-06-24 11:08:01.660 | INFO     | __main__:<module>:36 - epoch num: 69, loss: 444.6828281879425, val_precision: 0.4266355140186916, test_precision: 0.39211391018619934, learning_rate: 0.01, time: 62.1006817817688\n",
      "2019-06-24 11:09:03.661 | INFO     | __main__:<module>:36 - epoch num: 70, loss: 444.422080039978, val_precision: 0.43212616822429906, test_precision: 0.41073384446878425, learning_rate: 0.01, time: 61.98617744445801\n",
      "2019-06-24 11:10:05.714 | INFO     | __main__:<module>:36 - epoch num: 71, loss: 444.1193652153015, val_precision: 0.4475467289719626, test_precision: 0.4173055859802848, learning_rate: 0.01, time: 62.03840517997742\n",
      "2019-06-24 11:11:08.260 | INFO     | __main__:<module>:36 - epoch num: 72, loss: 442.786358833313, val_precision: 0.4549065420560748, test_precision: 0.42278203723986857, learning_rate: 0.01, time: 62.53248977661133\n",
      "2019-06-24 11:12:10.690 | INFO     | __main__:<module>:36 - epoch num: 73, loss: 442.27877402305603, val_precision: 0.41460280373831776, test_precision: 0.3822562979189485, learning_rate: 0.01, time: 62.41593551635742\n",
      "2019-06-24 11:13:13.188 | INFO     | __main__:<module>:36 - epoch num: 74, loss: 442.9084942340851, val_precision: 0.4503504672897196, test_precision: 0.40963855421686746, learning_rate: 0.01, time: 62.48319625854492\n",
      "2019-06-24 11:14:15.656 | INFO     | __main__:<module>:36 - epoch num: 75, loss: 441.6313695907593, val_precision: 0.4678738317757009, test_precision: 0.42716319824753557, learning_rate: 0.01, time: 62.452308654785156\n",
      "2019-06-24 11:15:18.236 | INFO     | __main__:<module>:36 - epoch num: 76, loss: 441.44506192207336, val_precision: 0.4716121495327103, test_precision: 0.42825848849945236, learning_rate: 0.01, time: 62.56553292274475\n",
      "2019-06-24 11:16:20.648 | INFO     | __main__:<module>:36 - epoch num: 77, loss: 440.8821268081665, val_precision: 0.45735981308411217, test_precision: 0.4403066812705367, learning_rate: 0.01, time: 62.39701461791992\n",
      "2019-06-24 11:17:23.017 | INFO     | __main__:<module>:36 - epoch num: 78, loss: 440.01977944374084, val_precision: 0.4396028037383178, test_precision: 0.39978094194961666, learning_rate: 0.01, time: 62.355249643325806\n",
      "2019-06-24 11:18:25.624 | INFO     | __main__:<module>:36 - epoch num: 79, loss: 440.1360535621643, val_precision: 0.45981308411214955, test_precision: 0.4304490690032859, learning_rate: 0.01, time: 62.583683252334595\n",
      "2019-06-24 11:19:28.033 | INFO     | __main__:<module>:36 - epoch num: 80, loss: 439.99150824546814, val_precision: 0.4800233644859813, test_precision: 0.4457831325301205, learning_rate: 0.01, time: 62.39441895484924\n",
      "2019-06-24 11:20:30.596 | INFO     | __main__:<module>:36 - epoch num: 81, loss: 440.28892374038696, val_precision: 0.4702102803738318, test_precision: 0.4414019715224535, learning_rate: 0.01, time: 62.549317598342896\n",
      "2019-06-24 11:21:33.198 | INFO     | __main__:<module>:36 - epoch num: 82, loss: 440.63780093193054, val_precision: 0.4844626168224299, test_precision: 0.452354874041621, learning_rate: 0.01, time: 62.587886571884155\n",
      "2019-06-24 11:22:35.661 | INFO     | __main__:<module>:36 - epoch num: 83, loss: 439.6924262046814, val_precision: 0.4427570093457944, test_precision: 0.4063526834611172, learning_rate: 0.01, time: 62.45126533508301\n",
      "2019-06-24 11:23:38.215 | INFO     | __main__:<module>:36 - epoch num: 84, loss: 440.10014390945435, val_precision: 0.4716121495327103, test_precision: 0.42716319824753557, learning_rate: 0.01, time: 62.53903412818909\n",
      "2019-06-24 11:24:40.673 | INFO     | __main__:<module>:36 - epoch num: 85, loss: 439.81358766555786, val_precision: 0.44871495327102806, test_precision: 0.4249726177437021, learning_rate: 0.01, time: 62.444316387176514\n",
      "2019-06-24 11:25:43.139 | INFO     | __main__:<module>:36 - epoch num: 86, loss: 439.20231771469116, val_precision: 0.4655373831775701, test_precision: 0.4370208105147864, learning_rate: 0.01, time: 62.4508171081543\n",
      "2019-06-24 11:26:45.766 | INFO     | __main__:<module>:36 - epoch num: 87, loss: 439.4850969314575, val_precision: 0.4501168224299065, test_precision: 0.4194961664841183, learning_rate: 0.01, time: 62.61284852027893\n",
      "2019-06-24 11:27:48.287 | INFO     | __main__:<module>:36 - epoch num: 88, loss: 439.38468647003174, val_precision: 0.4676401869158878, test_precision: 0.43263964950711936, learning_rate: 0.01, time: 62.50539779663086\n",
      "2019-06-24 11:28:50.744 | INFO     | __main__:<module>:36 - epoch num: 89, loss: 439.48182463645935, val_precision: 0.49077102803738315, test_precision: 0.447973713033954, learning_rate: 0.01, time: 62.443068742752075\n",
      "2019-06-24 11:29:53.212 | INFO     | __main__:<module>:36 - epoch num: 90, loss: 439.0605490207672, val_precision: 0.48317757009345796, test_precision: 0.44906900328587074, learning_rate: 0.01, time: 62.452852964401245\n",
      "2019-06-24 11:30:55.743 | INFO     | __main__:<module>:36 - epoch num: 91, loss: 439.2379686832428, val_precision: 0.40233644859813084, test_precision: 0.37349397590361444, learning_rate: 0.01, time: 62.517120122909546\n",
      "2019-06-24 11:31:58.088 | INFO     | __main__:<module>:36 - epoch num: 92, loss: 438.3994736671448, val_precision: 0.42184579439252334, test_precision: 0.4019715224534502, learning_rate: 0.01, time: 62.33060169219971\n",
      "2019-06-24 11:33:00.578 | INFO     | __main__:<module>:36 - epoch num: 93, loss: 438.50889468193054, val_precision: 0.4850467289719626, test_precision: 0.43811610076670315, learning_rate: 0.01, time: 62.47504687309265\n",
      "2019-06-24 11:34:03.086 | INFO     | __main__:<module>:36 - epoch num: 94, loss: 438.1753149032593, val_precision: 0.4877336448598131, test_precision: 0.45125958378970427, learning_rate: 0.01, time: 62.49240303039551\n",
      "2019-06-24 11:35:05.574 | INFO     | __main__:<module>:36 - epoch num: 95, loss: 438.0506865978241, val_precision: 0.44509345794392524, test_precision: 0.40963855421686746, learning_rate: 0.01, time: 62.47506070137024\n",
      "2019-06-24 11:36:08.176 | INFO     | __main__:<module>:36 - epoch num: 96, loss: 438.7905390262604, val_precision: 0.4679906542056075, test_precision: 0.42606790799561883, learning_rate: 0.01, time: 62.58652663230896\n",
      "2019-06-24 11:37:10.704 | INFO     | __main__:<module>:36 - epoch num: 97, loss: 437.64599418640137, val_precision: 0.4829439252336449, test_precision: 0.44359255202628695, learning_rate: 0.01, time: 62.51365947723389\n",
      "2019-06-24 11:38:13.222 | INFO     | __main__:<module>:36 - epoch num: 98, loss: 437.6647593975067, val_precision: 0.4919392523364486, test_precision: 0.45673603504928806, learning_rate: 0.01, time: 62.502514123916626\n",
      "2019-06-24 11:39:15.616 | INFO     | __main__:<module>:36 - epoch num: 99, loss: 437.2222397327423, val_precision: 0.48679906542056073, test_precision: 0.4249726177437021, learning_rate: 0.01, time: 62.37905502319336\n"
     ]
    }
   ],
   "source": [
    "prev_loss_list = PrevLoss()\n",
    "prev_loss = float('inf')\n",
    "for e in range(epoch):\n",
    "    need_save = False\n",
    "    start_time = time.time()\n",
    "    net.train()\n",
    "    train_dataset = utils.Dataset(root, train_df, input_length, num_class=num_class, label_dct=label_dct)\n",
    "    test_dataset =  utils.Dataset(root, test_df, input_length, num_class=num_class, label_dct=label_dct)\n",
    "    \n",
    "    train_data_iter = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    running_loss = 0.0\n",
    "    for i, (train_data, label) in enumerate(train_data_iter):\n",
    "        if use_cuda:\n",
    "            train_data = train_data.cuda()\n",
    "            label = label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        prediction = net(train_data)\n",
    "        loss = net.loss(prediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if e > 10:\n",
    "        prev_loss_list.append(running_loss)\n",
    "        prev_loss = prev_loss_list.value()\n",
    "        \n",
    "    if prev_loss < running_loss - 0.01:\n",
    "        learning_rate = learning_rate / 2\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    valid_train_res = validate(net, train_dataset, batch_size)\n",
    "    valid_test_res = validate(net, test_dataset, batch_size)\n",
    "    loss_dct = {'loss': running_loss}\n",
    "    val_precision = valid_train_res['precision']\n",
    "    test_precision = valid_test_res['precision']\n",
    "    logger.info(f'epoch num: {e}, loss: {running_loss}, val_precision: {val_precision}, test_precision: {test_precision}, learning_rate: {learning_rate}, time: {time.time() - start_time}')\n",
    "    visualizer.plot(loss_dct)\n",
    "    visualizer.plot({'val_precision': val_precision})\n",
    "    visualizer.plot({'test_precision': test_precision})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:experiment]",
   "language": "python",
   "name": "conda-env-experiment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
